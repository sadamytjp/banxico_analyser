{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banxico Analyser\n",
    "\n",
    "Banking on an earlier developed project, we aim to use natural language processing techniques to analyze every monetary policy statement that the Bank of Mexico (Banxico) has issued with regards to its monetary poliy stance (whether it raised, lowered or mantain unchanged its key policy rate). By doing so we expect to extract the frequency with which key words or groups of words (binominal, trinomial, etc) are used and extract a correlation between these counts and market fluctuations in response to them as well as between the counts and future policy decisions.\n",
    "\n",
    "We will be using python to transform the statements into processable text files, matplotlib and numpy to create the relevant indicators, correlations and graphs, and, as said, NLP to derive word ferquencies. Besides the statements, we have data on market interest rates and Banxico's policy rate readily available in Banxico's API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependencies\n",
    "%matplotlib inline\n",
    "import os\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "import json\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "from datetime import timedelta \n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/chromedriver\r\n"
     ]
    }
   ],
   "source": [
    "!which chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-01\n"
     ]
    }
   ],
   "source": [
    "#Variables\n",
    "start_date = \"2008-01-01\"\n",
    "initial_date = datetime(2008, 1, 1)\n",
    "end_date = (datetime.today() - timedelta(days = 4)).date()\n",
    "print(str(initial_date.date()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Banxico URL\n",
    "url = 'https://www.banxico.org.mx/publicaciones-y-prensa/anuncios-de-las-decisiones-de-politica-monetaria/anuncios-politica-monetaria-t.html'\n",
    "browser.visit(url)\n",
    "api_url = \"https://www.banxico.org.mx/SieAPIRest/service/v1/series/\"\n",
    "banxico_key = \"53a846791d89d8a66caece1024f75a984dda9317cbd533c085d1e1dac0f3779c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "links = []\n",
    "for link in soup.find_all('a'):\n",
    "    if ('/publicaciones-y-prensa/anuncios-de-las-decisiones-de-politica-monetaria') in link.get('href'):\n",
    "        partial_link = link.get('href')\n",
    "        links.append('http://www.banxico.org.mx' + partial_link)\n",
    "links = links[1:]\n",
    "#links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "for date in soup.find_all(\"td\"):\n",
    "    data = date.get_text()\n",
    "    dates.append(data)\n",
    "del dates[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "dates2 = []\n",
    "for index in range(len(dates)):\n",
    "    dates2.append(re.sub(\"\\s\", \"\", dates[index])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dates3 = []\n",
    "for index in range(len(dates)):\n",
    "    dates3.append(re.sub(\"[\\/]\", \"\", dates2[index])) \n",
    "#print(dates3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_counter = 0\n",
    "for i in links:\n",
    "    r = requests.get(i)\n",
    "    out_file = open(f'{dates3[name_counter]}.pdf', 'wb')\n",
    "    out_file.write(r.content)\n",
    "    name_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guillermo \n",
    "#pdf to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dates = []\n",
    "for date in dates2:\n",
    "    dates = datetime.strptime(date, \"%d/%m/%y\")\n",
    "    if dates > initial_date:\n",
    "        final_dates.append(datetime.strftime(dates, \"%Y-%m-%d\"))\n",
    "final_dates.append(datetime.strftime(end_date, \"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bmx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8263076f070a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murl_consulta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mfxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bmx\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"series\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"datos\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dato\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#tiempo del API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bmx'"
     ]
    }
   ],
   "source": [
    "#MXN Lvl\n",
    "Series = \"SF43788\"\n",
    "\n",
    "fxt = []\n",
    "for fecha in final_dates:\n",
    "    url_consulta = [f\"{api_url}{Series}/datos/{fecha}/{fecha}?token={banxico_key}\"]\n",
    "    for query in url_consulta: \n",
    "        data = requests.get(query).json()\n",
    "        fxt.append(data[\"bmx\"][\"series\"][0][\"datos\"][0][\"dato\"])\n",
    "time.sleep(180) #tiempo del API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tasa Obejtivo\n",
    "Series = \"SF43878\"\n",
    "\n",
    "tasa = []\n",
    "for fecha in final_dates:\n",
    "    try:\n",
    "        url_consulta = [f\"{api_url}{Series}/datos/{fecha}/{fecha}?token={banxico_key}\"]\n",
    "        for query in url_consulta: \n",
    "            data = requests.get(query).json()\n",
    "            tasa.append(data[\"bmx\"][\"series\"][0][\"datos\"][0][\"dato\"])\n",
    "    except:\n",
    "        tasa.append(0)\n",
    "time.sleep(180) #tiempo del API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inflacion\n",
    "Series = \"SP30578\"\n",
    "\n",
    "#Total Data\n",
    "total_query_url = f\"{api_url}{Series}/datos/{start_date}/{end_date}?token={banxico_key}\"\n",
    "total_data = requests.get(total_query_url).json()\n",
    "print(total_data)\n",
    "data_total = total_data['bmx']['series'][0]['datos']\n",
    "data_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Match fechas\n",
    "data_total_df = pd.DataFrame(data_total)\n",
    "data_total_df['fecha'] = pd.to_datetime(data_total_df['fecha'], format='%d/%m/%Y')\n",
    "data_total_df['key'] = pd.to_datetime(data_total_df['fecha']).dt.to_period('M')\n",
    "data_total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_banxico_dict = {\"MXN\": fxt,  \"Tasa\": tasa}\n",
    "pre_banxico_df = pd.DataFrame(pre_banxico_dict)\n",
    "pre_banxico_df['Fecha'] = final_dates\n",
    "pre_banxico_df['key'] = pd.to_datetime(pre_banxico_df['Fecha']).dt.to_period('M')\n",
    "pre_banxico_df = pre_banxico_df.sort_values('Fecha')\n",
    "pre_banxico_df = pre_banxico_df[pre_banxico_df.Tasa != 0]\n",
    "pre_banxico_df = pre_banxico_df.reset_index(drop = True)\n",
    "pre_banxico_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banxico_merge = data_total_df.merge(pre_banxico_df, on='key')\n",
    "banxico_merge['Tasa'] = banxico_merge['Tasa'].astype(float)\n",
    "banxico_merge['Dif'] = 0\n",
    "banxico_merge.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix Array\n",
    "banxico_merge.rename(columns = {'dato':'Inflacion'}, inplace = True) \n",
    "banxico_merge = banxico_merge.reset_index(drop = True)\n",
    "banxico_merge = banxico_merge.drop(['fecha', 'key'], axis = 1) \n",
    "banxico_merge['Tasa'] = banxico_merge['Tasa'].astype(float)\n",
    "banxico_merge = banxico_merge[['Fecha', 'MXN', 'Inflacion', 'Tasa', 'Dif']]\n",
    "banxico_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(banxico_merge) -1 ):\n",
    "    banxico_merge.loc[i, 'Dif'] = 25 * round((100 * (banxico_merge.loc[i, 'Tasa'] - banxico_merge.loc[i-1, 'Tasa']))/25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banxico_merge['key'] = pd.to_datetime(banxico_merge['Fecha']).dt.to_period('M')\n",
    "banxico_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import frecuencias_banxico.csv\n",
    "frecuencias_df = pd.read_csv('frecuencias_banxico.csv')\n",
    "frecuencias_df.rename(columns={'Unnamed: 0':'name'}, inplace=True)\n",
    "frecuencias_df['key'] = frecuencias_df['name'].str.replace('count',\"\")\n",
    "frecuencias_df['key'] = pd.to_datetime(frecuencias_df['key'].astype(str), format='%d%m%y')\n",
    "frecuencias_df['key'] = pd.to_datetime(frecuencias_df['key']).dt.to_period('M')\n",
    "frecuencias_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banxico_merge = banxico_merge.merge(frecuencias_df, on='key')\n",
    "banxico_merge = banxico_merge.drop(['name', 'key'], axis = 1)\n",
    "banxico_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"FX vs. Interest Rate\"\n",
    "plt.scatter(banxico_merge[\"MXN\"], banxico_merge[\"Tasa\"], marker = \"o\", color=\"blue\")\n",
    "plt.title(title, size=13)\n",
    "plt.xlabel(\"FX (Pesos per dollar)\")\n",
    "plt.ylabel(\"Interest Rate (%)\")\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"{title}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "title = \"Inflation counts vs. FX Regression\"\n",
    "x = banxico_merge[\"inflacion\"]\n",
    "y = banxico_merge[\"MXN\"]\n",
    "(slope, intercept, rvalue, pvalue, stderr) = linregress(x, y)\n",
    "regress_values = x * slope + intercept\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,regress_values,\"r-\")\n",
    "plt.annotate(line_eq,(17,18.8),fontsize=15,color=\"red\")\n",
    "plt.title(title)\n",
    "plt.xlabel('Inflation counts')\n",
    "plt.ylabel(\"FX (pesos per dollar)\")\n",
    "plt.savefig(f\"{title}.png\")\n",
    "print(f\"The r-squared is: {rvalue}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Aqui va como x \"inflacion\" (la del conteo, no la de los números) y la tasa de interés (no el diferencial)\n",
    "title = \"Inflation counts vs. Interest Rate Regression\"\n",
    "x = banxico_merge[\"inflacion\"]\n",
    "y = banxico_merge[\"Tasa\"]\n",
    "(slope, intercept, rvalue, pvalue, stderr) = linregress(x, y)\n",
    "regress_values = x * slope + intercept\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,regress_values,\"r-\")\n",
    "plt.annotate(line_eq,(20,7.7),fontsize=15,color=\"red\")\n",
    "plt.title(title)\n",
    "plt.xlabel('Inflation counts')\n",
    "plt.ylabel(\"Interest Rate (%)\")\n",
    "plt.savefig(f\"{title}.png\")\n",
    "print(f\"The r-squared is: {rvalue}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Economic slack counts vs. Interest Rate Regression\"\n",
    "x = banxico_merge[\"holgura\"]*-1\n",
    "y = banxico_merge[\"Tasa\"]\n",
    "(slope, intercept, rvalue, pvalue, stderr) = linregress(x, y)\n",
    "regress_values = x * slope + intercept\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,regress_values,\"r-\")\n",
    "plt.annotate(line_eq,(2,7.7),fontsize=15,color=\"red\")\n",
    "plt.title(title)\n",
    "plt.xlabel('Economic slack counts')\n",
    "plt.ylabel(\"Interest Rate (%)\")\n",
    "plt.savefig(f\"{title}.png\")\n",
    "print(f\"The r-squared is: {rvalue}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Aggregate Concern Index vs. Interest Rate\"\n",
    "x = banxico_merge[\"index\"]\n",
    "y = banxico_merge[\"Tasa\"]\n",
    "(slope, intercept, rvalue, pvalue, stderr) = linregress(x, y)\n",
    "regress_values = x * slope + intercept\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,regress_values,\"r-\")\n",
    "plt.annotate(line_eq,(15,7.7),fontsize=15,color=\"red\")\n",
    "plt.title(title)\n",
    "plt.xlabel('Index (higher = more concern)')\n",
    "plt.ylabel(\"Interest Rate (%)\")\n",
    "plt.savefig(f\"{title}.png\")\n",
    "print(f\"The r-squared is: {rvalue}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify data anomalities\n",
    "banxico_merge.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoding\n",
    "#banxico_clean = pd.get_dummies(banxico_merge)\n",
    "#banxico_clean.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign target and variables\n",
    "target = np.array(banxico_merge['Dif'])\n",
    "variables = banxico_merge.drop([\"Dif\", \"Fecha\"], axis = 1)\n",
    "variable_list = list(variables.columns)\n",
    "variables = np.array(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "train_variables, test_variables, train_target, test_target = train_test_split(variables, target, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Variables Shape:', train_variables.shape)\n",
    "print('Training TArget Shape:', train_target.shape)\n",
    "print('Testing Variables Shape:', test_variables.shape)\n",
    "print('Testing TArget Shape:', test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "classifier  = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "classifier.fit(train_variables, train_target);\n",
    "classifier.fit(variables, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = classifier .predict(test_variables)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_target)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'Basicos.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get VAriable importances\n",
    "importances = list(classifier .feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(variable_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib for plotting and use magic command for Jupyter Notebooks\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, variable_list, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(variables)\n",
    "print(f\"First 10 Predictions:   {predictions[:10]}\")\n",
    "print(f\"First 10 Actual labels: {test_target[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
